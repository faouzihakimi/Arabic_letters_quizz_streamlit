{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training for arabic character recognition app\n",
    "\n",
    "## 1. Librairies and data\n",
    "\n",
    "To make the code work, you need to download the data (csvTrain and csvTest images and labels) here :  https://www.kaggle.com/datasets/mloey1/ahcd1/data?select=Train%2BTest+Images+Matlab.mat\n",
    "\n",
    "Then, import it in a folder named \"data.  We can now load the librairies we need for this project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, metrics\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "#Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cann now load the arabic letters datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train dataset\n",
    "X_train = pd.read_csv(\"data/csvTrainImages 13440x1024.csv\")\n",
    "y_train = pd.read_csv(\"data/csvTrainLabel 13440x1.csv\")\n",
    "y_train = y_train -1 #labels start from 0\n",
    "\n",
    "#Test dataset\n",
    "X_test = pd.read_csv(\"data/csvTestImages 3360x1024.csv\")\n",
    "y_test = pd.read_csv(\"data/csvTestLabel 3360x1.csv\")\n",
    "y_test = y_test -1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plot an exemple of the training data. You can change the number \"30\" by any number between 0 and 13438."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_ex = np.array(X_train)[30].reshape(32, 32)\n",
    "#reverse each column\n",
    "image_ex= image_ex.T #to get the character as it is read\n",
    "\n",
    "plt.imshow(image_ex, cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation and model architecture\n",
    "\n",
    "Since the data set comes directly from kaggle, it is already clean (no duplicates or incomplete data) and ready to be use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data for deep learning\n",
    "X_train_DL = np.array(X_train).reshape((X_train.shape[0], 32, 32, 1))\n",
    "X_test_DL = np.array(X_test).reshape((X_test.shape[0], 32, 32, 1))\n",
    "X_train_DL = X_train_DL.astype('float32') / 255\n",
    "X_test_DL = X_test_DL.astype('float32') / 255\n",
    "\n",
    "# Convert labels to categorical for compatibility with Keras\n",
    "num_classes = 28\n",
    "y_train_DL = to_categorical(y_train, num_classes)\n",
    "y_test_cat_DL = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen model architecture is a Convolutional Neural Network (CNN) designed for image classification tasks (32x32 grayscale images).The model consists of three convolutional layers, each followed by max pooling, then a flatten layer, a dense layer with dropout for regularization, and finally an output layer. The use of ReLU activation and He uniform initialization in the convolutional and dense layers helps in training deep networks effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model architecture\n",
    "\n",
    "model = Sequential([\n",
    "    # First Convolutional Layer\n",
    "    # 32 filters, 3x3 kernel size, ReLU activation, He uniform initialization\n",
    "    # Input shape: 32x32 grayscale images (1 channel)\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 1)),\n",
    "    \n",
    "    # Max Pooling Layer\n",
    "    # Reduces spatial dimensions by half\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Second Convolutional Layer\n",
    "    # 64 filters, 3x3 kernel size, ReLU activation, He uniform initialization\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'),\n",
    "    \n",
    "    # Max Pooling Layer\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Third Convolutional Layer\n",
    "    # 64 filters, 3x3 kernel size, ReLU activation, He uniform initialization\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'),\n",
    "    \n",
    "    # Flatten Layer\n",
    "    # Converts the 2D feature maps to a 1D vector\n",
    "    Flatten(),\n",
    "    \n",
    "    # First Dense Layer\n",
    "    # 128 neurons, ReLU activation, He uniform initialization\n",
    "    Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "    \n",
    "    # Dropout Layer\n",
    "    # Helps prevent overfitting by randomly setting 50% of inputs to 0\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    # Output Layer\n",
    "    # Number of neurons equals number of classes, Softmax activation for multi-class classification\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training and save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given code compiles, trains, and evaluates a neural network model:\n",
    "\n",
    "1. **Compile**: Uses the Adam optimizer with a learning rate of 0.001 and categorical crossentropy loss.\n",
    "2. **Summary**: Displays the model architecture and parameters.\n",
    "3. **Train**: Fits the model on training data for 20 epochs with a batch size of 32, using 10% of the data for validation.\n",
    "4. **Evaluate**: Assesses model performance on test data and prints the test accuracy.\n",
    "\n",
    "\n",
    "This process prepares the model for training and measures its effectiveness on unseen data. The proposed hyperparameters are standard, but could be optimized for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_DL, y_train_DL, epochs=20, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_DL, y_test_cat_DL, verbose=0)\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then save the obtained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('app/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model loading, evaluation, and test with visualisation on a image prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('app/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "y_pred_DL = model.predict(X_test_DL)\n",
    "y_pred_classes_DL = np.argmax(y_pred_DL, axis=1)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_DL, y_test_cat_DL, verbose=0)\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test prediction on a single image. You can replace the '3' by any number to test on a different image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test = np.array(X_test)[3].reshape(32, 32, 1)\n",
    "image_test = image_test.astype('float32') / 255\n",
    "\n",
    "# Make predictions on the test image\n",
    "y_pred_DL = model.predict(image_test.reshape(1, 32, 32, 1))\n",
    "y_pred_classes_DL = np.argmax(y_pred_DL, axis=1)\n",
    "print(y_pred_classes_DL[0])\n",
    "\n",
    "# Plot the image\n",
    "import matplotlib.pyplot as plt\n",
    "image_test = image_test.T\n",
    "plt.imshow(image_test.reshape(32, 32), cmap='binary')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
